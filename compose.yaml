services:
  frontend:
    build:
      context: ./frontend
      dockerfile: ../Dockerfile.js
    ports:
      - "59001:59001"
    volumes:
      - ./frontend:/app
  backend: &backend-base
    build:
      context: ./backend
      dockerfile: ../Dockerfile.python
    ports:
      - "59002:59002"
    environment:
      AF_DB_PATH: /app/save.db
      AF_DB_KEY: ${AF_DB_KEY}
    volumes:
      - ./backend:/app
      # Mount user's cache into container so backend and LLM variants can reuse cached models/files
      - ${HOME}/.cache:/root/.cache:delegated
  backend-llm-cuda:
    <<: *backend-base
    build:
      context: ./backend
      dockerfile: ../Dockerfile.python
      args:
        UV_EXTRA: llm-cuda
    ports:
      - "59002:59002" # conflicts with default backend
    profiles:
      - llm-cuda
  backend-llm-amd:
    <<: *backend-base
    build:
      context: ./backend
      dockerfile: ../Dockerfile.python
      args:
        UV_EXTRA: llm-amd
    ports:
      - "59002:59002" # conflicts with default backend
    profiles:
      - llm-amd
  backend-llm-cpu:
    <<: *backend-base
    build:
      context: ./backend
      dockerfile: ../Dockerfile.python
      args:
        UV_EXTRA: llm-cpu
    ports:
      - "59002:59002" # conflicts with default backend
    profiles:
      - llm-cpu
